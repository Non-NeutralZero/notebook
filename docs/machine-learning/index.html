<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Machine Learning
  #

Section renders pages in section as definition list, using title and description. Optional param summary can be used to show or hide page summary


  
    Decision Trees
  
  
    
  Decision Trees
  #


On each node, a decision tree asks a question and answers it with yes/no to classify observations under that node.
The question could be based on a specific True/False (is obs.feature = something) question or could be based on numeric data (is obs.feature > 10)

"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://non-neutralzero.github.io/notebook/docs/machine-learning/"><meta property="og:site_name" content="Digital Notebook NonNeutralZero"><meta property="og:title" content="Digital Notebook NonNeutralZero"><meta property="og:description" content=" Machine Learning # Section renders pages in section as definition list, using title and description. Optional param summary can be used to show or hide page summary
Decision Trees Decision Trees # On each node, a decision tree asks a question and answers it with yes/no to classify observations under that node. The question could be based on a specific True/False (is obs.feature = something) question or could be based on numeric data (is obs.feature > 10) "><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>Machine Learning | Digital Notebook NonNeutralZero</title>
<link rel=manifest href=/notebook/manifest.json><link rel=icon href=/notebook/favicon.png><link rel=stylesheet href=/notebook/book.min.33a48f5432973b8ff9a82679d9e45d67f2c15d4399bd2829269455cfe390b5e8.css integrity="sha256-M6SPVDKXO4/5qCZ52eRdZ/LBXUOZvSgpJpRVz+OQteg=" crossorigin=anonymous><script defer src=/notebook/flexsearch.min.js></script><script defer src=/notebook/en.search.min.a0c0044ca1c9f09f1b29ef02ce7c15846f893d7fed05be21f41864b2976785a3.js integrity="sha256-oMAETKHJ8J8bKe8CznwVhG+JPX/tBb4h9BhkspdnhaM=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://non-neutralzero.github.io/notebook/docs/machine-learning/index.xml title="Digital Notebook NonNeutralZero"></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/notebook/><span>Digital Notebook NonNeutralZero</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-d70a1da63cb07790d45cd1070740b6fc class=toggle>
<label for=section-d70a1da63cb07790d45cd1070740b6fc class="flex justify-between"><a href=/notebook/docs/data-science/>Data Science</a></label><ul><li><a href=/notebook/docs/data-science/churn/churn-problem-framing/>Churn Problem Framing</a></li><li><a href=/notebook/docs/data-science/churn/churn/>Churn</a></li><li><a href=/notebook/docs/data-science/feature-engineering/feature-store/>Feature Store</a></li><li><a href=/notebook/docs/data-science/outlier-detection/>Outlier Detection</a></li><li><a href=/notebook/docs/data-science/sna/sna/>SNA</a></li></ul></li><li><input type=checkbox id=section-ea80d2588ab2432c68a3e3a3b032af95 class=toggle checked>
<label for=section-ea80d2588ab2432c68a3e3a3b032af95 class="flex justify-between"><a href=/notebook/docs/machine-learning/ class=active>Machine Learning</a></label><ul><li><a href=/notebook/docs/machine-learning/decision-trees/>Decision Trees</a></li><li><a href=/notebook/docs/machine-learning/explainability-snippets/>Explainability Snippets</a></li><li><a href=/notebook/docs/machine-learning/random-forests/>Random Forests</a></li><li><a href=/notebook/docs/machine-learning/svm/>Svm</a></li></ul></li><li><input type=checkbox id=section-fc1f94a4a6ef88f123f49cedfce9f479 class=toggle>
<label for=section-fc1f94a4a6ef88f123f49cedfce9f479 class="flex justify-between"><a href=/notebook/docs/deep-learning/>Deep Learning</a></label><ul><li><a href=/notebook/docs/deep-learning/logregnn/logregnn/>Log Reg Nn</a></li><li><a href=/notebook/docs/deep-learning/noprop/noprop/>No Prop</a></li></ul></li></ul><ul><li><a href=/notebook/posts/>Knowledge Base</a></li><li><a href=https://github.com/Non-NeutralZero target=_blank rel=noopener>Github</a></li><li><a href=https://nonneutralzero.com target=_blank rel=noopener>NonNeutralZero</a></li><li><a href=https://linktr.ee/nonneutralzero target=_blank rel=noopener>Linktree</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/notebook/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Machine Learning</strong>
<label for=toc-control><img src=/notebook/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class=markdown><h1 id=machine-learning>Machine Learning
<a class=anchor href=#machine-learning>#</a></h1><p>Section renders pages in section as definition list, using title and description. Optional param <code>summary</code> can be used to show or hide page summary</p><dl><dt><a href=/notebook/docs/machine-learning/decision-trees/>Decision Trees</a></dt><dd class=markdown-inner><h1 id=decision-trees>Decision Trees
<a class=anchor href=#decision-trees>#</a></h1><ul><li>On each node, a decision tree asks a question and answers it with yes/no to classify observations under that node.</li><li>The question could be based on a specific True/False <em>(is obs.feature = something)</em> question or could be based on numeric data <em>(is obs.feature > 10)</em></li></ul><p><img src=https://upload.wikimedia.org/wikipedia/commons/f/ff/Decision_tree_model.png alt="Decision tree example"></p><ul><li>The classification can be categorical or numerical</li><li>The first node is called the <strong>Root node</strong>, the nodes in the middle are called <strong>internal nodes</strong>, and the results are called <strong>leaf nodes</strong></li></ul></dd><dt><a href=/notebook/docs/machine-learning/explainability-snippets/>Explainability Snippets</a></dt><dd class=markdown-inner><p>version 2018</p><h3 id=why-model-interpretation>Why Model interpretation?
<a class=anchor href=#why-model-interpretation>#</a></h3><p>Understanding how a model makes decisions — model interpretation — has been on the front burner since the end of 2017. Decision support systems and models they are based on don’t explain which features influenced their decisions were known as black boxes.
Model interpretability is not only important for companies that need to fulfill legal obligations to customers. It serves a technical purpose as well. Every ML model considers input features (problem properties) to predict results (outputs). The more relevant features we create and use to train an ML model during feature engineering, the more accurate results we can get and the simpler our model is. That’s why the ability to understand how the model makes predictions is crucial for its debugging.
<a href=https://www.kdnuggets.com/2019/02/ai-data-science-advances-trends.html>source</a></p></dd><dt><a href=/notebook/docs/machine-learning/random-forests/>Random Forests</a></dt><dd class=markdown-inner><h1 id=random-forest>Random Forest
<a class=anchor href=#random-forest>#</a></h1><p>Random forests are built from decision trees</p><ol><li>Initially, the original data is bootstrapped by randomly sampling the data and creating a new dataset with the same size as the original one (to be able to do that, duplicated obs are allowed - aka random sampling with replacement)</li><li>Build a decision tree based on the bootsrapped data</li><li>Randomly select features (typically sqrt(n_features)) from the bootsrapped data when splitting nodes (this is called random subspace method)</li><li>Go back to step 1 and repeat</li></ol><ul><li><em><strong>does all the original data end up in the sampled subsets?</strong></em> For each created Decision Tree, the non-bootsrapped data is called <strong>Out-of-Bag</strong> data.</li><li><em><strong>once we get the forest, how do we use it?</strong></em> if we want to get a prediction, we run an obs through all the trees of the forest and pick the prediction with the most votes. (this process is called <strong>Bagging</strong>, i.e. <strong>B</strong>ootsrapping + <strong>agg</strong>regating single predictions)</li><li><em><strong>how do we evaluate the random forest?</strong></em> we can evaluate it using the out-of-bag error, i.e. measure how accurate the forest predicts out-of-bag data.</li><li><em><strong>is there an optimal number of features for each bootsrapped sample?</strong></em> Yes. Given that we can measure the out-of-bag error, we can use it to compare forests built on different samples of features and select the one with the smallest error.</li><li><em><strong>how many times should we repeat this processes?</strong></em> plot OOB error rate vs. number of trees</li><li><em><strong>Why are they called random forests?</strong></em> Because of the random sampling concept at step 1 and at step 3</li><li><em><strong>how is a forest better than one decision tree?</strong></em> By getting a large number of different (high variance ) trees</li></ul><p>For more, see Chapter 15 in <a href=https://web.stanford.edu/~hastie/Papers/ESLII.pdf>https://web.stanford.edu/~hastie/Papers/ESLII.pdf</a></p></dd><dt><a href=/notebook/docs/machine-learning/svm/>Svm</a></dt><dd class=markdown-inner><h1 id=svm>SVM
<a class=anchor href=#svm>#</a></h1><ul><li>P: <em><strong>We want to figure out a way to separate data into classes</strong></em></li><li>S: A linear classifier can help. Its objective would be to divide data using a hyperplane, and since the data points, from each class, that are closer to the classifier will be helping us decide on the orientation and position of the classifier, we can give them a fancy name (Support vectors) and call our linear classifier, the Support Vector Classifier.</li><li>P: <em><strong>But, If the data is &ldquo;clearly&rdquo; separable, then we won&rsquo;t have one classifier - we would actually end up with so many possibilities to choosing one hyperplane AND we have to make sure future predictions are more likely to be correctly classified</strong></em></li><li>S: We could choose the one that insures the maximum distance between the Support vectors of the two classes (we&rsquo;ll call it a <strong>maximum margin classifier</strong>.) That way, we&rsquo;ll seperate the existing data, and have more confidence in classifying future data points.</li><li>P: <em><strong>We&rsquo;ll be looking to maximize the margin between the data points and the hyperplane, how do we do that?</strong></em></li><li>S: Hinge Loss!</li><li>P: <em><strong>Overfitting, this type of classifier would be very sensitive to outliers for example</strong></em></li><li>S: Explorative data analysis, outliers analysis or allow misclassification (soft margin). o</li></ul></dd></dl></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>